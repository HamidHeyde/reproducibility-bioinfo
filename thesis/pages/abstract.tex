\begin{abstract}
  Reproducibility, the ability to reproduce computational results using identical data and software, 
is a cornerstone of the scientific methodology. However, through the past decade, several studies 
revealed a widespread lack of results’ reproducibility, to the point that the existence of a 
reproducibility crisis is now acknowledged in various fields.
In Machine Learning, given the flexibility available in various phases of constructing a 
computational model, the experiments are not immune to reproducibility issues either. 
In case of imbalance learning for problems with multiple classes, the problem is even more 
severe since there are more parameters in play for constructing a model. This type of problems can be 
found in various disciplines including bioinformatics, the primary focus of our study.


Researchers have done several studies proposing various recommendations for having results’ 
reproducibility for problems in this field. Some conferences like NeurIPS have even adopted 
new measures in that regard. Following those guidelines could ensure reproducibility in 
balanced problems, in case of imbalance learning for problems with multiple classes we 
believe more details are required on the study report.
In this work we demonstrate that, in an imbalanced scenario, even in its basic form, 
a study report with a fair amount of details, could reproduce a wide range of results if 
some model details are missed on the report. We also tried using different libraries for 
the same classification algorithm to see how and to what extent that would affect the final results 
in different scenarios.  
\end{abstract}