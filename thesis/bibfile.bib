
@article{galar_review_2012,
	title = {A {Review} on {Ensembles} for the {Class} {Imbalance} {Problem}: {Bagging}-, {Boosting}-, and {Hybrid}-{Based} {Approaches}},
	volume = {42},
	issn = {1094-6977, 1558-2442},
	shorttitle = {A {Review} on {Ensembles} for the {Class} {Imbalance} {Problem}},
	url = {http://ieeexplore.ieee.org/document/5978225/},
	doi = {10.1109/TSMCC.2011.2161285},
	number = {4},
	urldate = {2021-03-31},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
	author = {Galar, M. and Fernandez, A. and Barrenechea, E. and Bustince, H. and Herrera, F.},
	month = jul,
	year = {2012},
	pages = {463--484},
}

@article{ling_test_2006,
	title = {Test strategies for cost-sensitive decision trees},
	volume = {18},
	issn = {1041-4347},
	url = {http://ieeexplore.ieee.org/document/1644729/},
	doi = {10.1109/TKDE.2006.131},
	number = {8},
	urldate = {2021-03-31},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Ling, C.X. and Sheng, V.S. and Yang, Q.},
	month = aug,
	year = {2006},
	pages = {1055--1067},
}

@article{chawla_automatically_2008,
	title = {Automatically countering imbalance and its empirical relationship to cost},
	volume = {17},
	issn = {1384-5810, 1573-756X},
	url = {http://link.springer.com/10.1007/s10618-008-0087-0},
	doi = {10.1007/s10618-008-0087-0},
	language = {en},
	number = {2},
	urldate = {2021-03-31},
	journal = {Data Mining and Knowledge Discovery},
	author = {Chawla, Nitesh V. and Cieslak, David A. and Hall, Lawrence O. and Joshi, Ajay},
	month = oct,
	year = {2008},
	pages = {225--252},
}

@article{fernandez_study_2008,
	title = {A study of the behaviour of linguistic fuzzy rule based classification systems in the framework of imbalanced data-sets},
	volume = {159},
	issn = {01650114},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165011407005660},
	doi = {10.1016/j.fss.2007.12.023},
	language = {en},
	number = {18},
	urldate = {2021-03-31},
	journal = {Fuzzy Sets and Systems},
	author = {Fernández, Alberto and García, Salvador and del Jesus, María José and Herrera, Francisco},
	month = sep,
	year = {2008},
	pages = {2378--2398},
}

@article{batista_study_2004,
	title = {A study of the behavior of several methods for balancing machine learning training data},
	volume = {6},
	issn = {1931-0145, 1931-0153},
	url = {https://dl.acm.org/doi/10.1145/1007730.1007735},
	doi = {10.1145/1007730.1007735},
	abstract = {There are several aspects that might influence the performance achieved by existing learning systems. It has been reported that one of these aspects is related to class imbalance in which examples in training data belonging to one class heavily outnumber the examples in the other class. In this situation, which is found in real world data describing an infrequent but important event, the learning system may have difficulties to learn the concept related to the minority class. In this work we perform a broad experimental evaluation involving ten methods, three of them proposed by the authors, to deal with the class imbalance problem in thirteen UCI data sets. Our experiments provide evidence that class imbalance does not systematically hinder the performance of learning systems. In fact, the problem seems to be related to learning with too few minority class examples in the presence of other complicating factors, such as class overlapping. Two of our proposed methods deal with these conditions directly, allying a known over-sampling method with data cleaning methods in order to produce better-defined class clusters. Our comparative experiments show that, in general, over-sampling methods provide more accurate results than under-sampling methods considering the area under the ROC curve (AUC). This result seems to contradict results previously published in the literature. Two of our proposed methods, Smote + Tomek and Smote + ENN, presented very good results for data sets with a small number of positive examples. Moreover, Random over-sampling, a very simple over-sampling method, is very competitive to more complex over-sampling methods. Since the over-sampling methods provided very good performance results, we also measured the syntactic complexity of the decision trees induced from over-sampled data. Our results show that these trees are usually more complex then the ones induced from original data. Random over-sampling usually produced the smallest increase in the mean number of induced rules and Smote + ENN the smallest increase in the mean number of conditions per rule, when compared among the investigated over-sampling methods.},
	language = {en},
	number = {1},
	urldate = {2021-03-31},
	journal = {ACM SIGKDD Explorations Newsletter},
	author = {Batista, Gustavo E. A. P. A. and Prati, Ronaldo C. and Monard, Maria Carolina},
	month = jun,
	year = {2004},
	pages = {20--29},
}

@article{barandela_2003,
	title = {Strategies for learning in class imbalance problems},
	volume = {36},
	issn = {00313203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320302002571},
	doi = {10.1016/S0031-3203(02)00257-1},
	language = {en},
	number = {3},
	urldate = {2021-03-31},
	journal = {Pattern Recognition},
	author = {Barandela, R and Sánchez, J.S and Garcı́a, V and Rangel, E},
	month = mar,
	year = {2003},
	pages = {849--851},
}

@article{lin_support_2002,
	title = {Support {Vector} {Machines} for {Classification} in {Nonstandard} {Situations}},
	volume = {46},
	issn = {08856125},
	url = {http://link.springer.com/10.1023/A:1012406528296},
	doi = {10.1023/A:1012406528296},
	number = {1/3},
	urldate = {2021-03-31},
	journal = {Machine Learning},
	author = {Lin, Yi and Lee, Yoonkyung and Wahba, Grace},
	year = {2002},
	pages = {191--202},
}

@incollection{hutchison_imbalanced_2004,
	address = {Berlin, Heidelberg},
	title = {The {Imbalanced} {Training} {Sample} {Problem}: {Under} or over {Sampling}?},
	volume = {3138},
	isbn = {978-3-540-22570-6 978-3-540-27868-9},
	shorttitle = {The {Imbalanced} {Training} {Sample} {Problem}},
	url = {http://link.springer.com/10.1007/978-3-540-27868-9_88},
	urldate = {2021-03-31},
	booktitle = {Structural, {Syntactic}, and {Statistical} {Pattern} {Recognition}},
	publisher = {Springer Berlin Heidelberg},
	author = {Barandela, Ricardo and Valdovinos, Rosa M. and Sánchez, J. Salvador and Ferri, Francesc J.},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Fred, Ana and Caelli, Terry M. and Duin, Robert P. W. and Campilho, Aurélio C. and de Ridder, Dick},
	year = {2004},
	doi = {10.1007/978-3-540-27868-9_88},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {806--814},
}

@article{garcia_k-nn_2008,
	title = {On the k-{NN} performance in a challenging scenario of imbalance and overlapping},
	volume = {11},
	issn = {1433-7541, 1433-755X},
	url = {http://link.springer.com/10.1007/s10044-007-0087-5},
	doi = {10.1007/s10044-007-0087-5},
	language = {en},
	number = {3-4},
	urldate = {2021-03-31},
	journal = {Pattern Analysis and Applications},
	author = {García, V. and Mollineda, R. A. and Sánchez, J. S.},
	month = sep,
	year = {2008},
	pages = {269--280},
}

@book{fernandez_learning_2018,
	address = {Cham},
	title = {Learning from {Imbalanced} {Data} {Sets}},
	isbn = {9783319980737 9783319980744},
	url = {http://link.springer.com/10.1007/978-3-319-98074-4},
	language = {en},
	urldate = {2021-03-31},
	publisher = {Springer International Publishing},
	author = {Fernández, Alberto and García, Salvador and Galar, Mikel and Prati, Ronaldo C. and Krawczyk, Bartosz and Herrera, Francisco},
	year = {2018},
	doi = {10.1007/978-3-319-98074-4},
}

@book{james_introduction_2013,
	address = {New York},
	series = {Springer texts in statistics},
	title = {An introduction to statistical learning: with applications in {R}},
	isbn = {9781461471370},
	shorttitle = {An introduction to statistical learning},
	number = {103},
	publisher = {Springer},
	editor = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
	year = {2013},
	note = {OCLC: ocn828488009},
	keywords = {Mathematical models, Mathematical statistics, Problems, exercises, etc, R (Computer program language), Statistics},
}

@article{provost_machine_2000,
	title = {Machine {Learning} from {Imbalanced} {Data} {Sets} 101 {Extended}},
	volume = {68},
	url = {https://www.aaai.org/Papers/Workshops/2000/WS-00-05/WS00-05-001.pdf},
	language = {English},
	journal = {Proceedings of the AAAI’2000 workshop on imbalanced data sets},
	author = {Provost, Foster},
	year = {2000},
	pages = {1--3},
}

@article{sokolova_systematic_2009,
	title = {A systematic analysis of performance measures for classification tasks},
	volume = {45},
	issn = {03064573},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306457309000259},
	doi = {10.1016/j.ipm.2009.03.002},
	language = {en},
	number = {4},
	urldate = {2021-03-29},
	journal = {Information Processing \& Management},
	author = {Sokolova, Marina and Lapalme, Guy},
	month = jul,
	year = {2009},
	pages = {427--437},
}

@article{chawla_editorial_2004,
	title = {Editorial: special issue on learning from imbalanced data sets},
	volume = {6},
	issn = {1931-0145, 1931-0153},
	shorttitle = {Editorial},
	url = {https://dl.acm.org/doi/10.1145/1007730.1007733},
	doi = {10.1145/1007730.1007733},
	language = {en},
	number = {1},
	urldate = {2021-03-08},
	journal = {ACM SIGKDD Explorations Newsletter},
	author = {Chawla, Nitesh V. and Japkowicz, Nathalie and Kotcz, Aleksander},
	month = jun,
	year = {2004},
	pages = {1--6},
}

@inproceedings{japkowicz_concept-learning_2001,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Concept-{Learning} in the {Presence} of {Between}-{Class} and {Within}-{Class} {Imbalances}},
	isbn = {9783540451532},
	doi = {10.1007/3-540-45153-6_7},
	abstract = {In a concept learning problem, imbalances in the distribution of the data can occur either between the two classes or within a single class. Yet, although both types of imbalances are known to affect negatively the performance of standard classifiers, methods for dealing with the class imbalance problem usually focus on rectifying the between-class imbalance problem, neglecting to address the imbalance occurring within each class. The purpose of this paper is to extend the simplest proposed approach for dealing with the between-class imbalance problem—random re—sampling in order to deal simultaneously with the two problems. Although re-sampling is not necessarily the best way to deal with problems of imbalance, the results reported in this paper suggest that addressing both problems simultaneously is beneficial and should be done by more sophisticated techniques as well.},
	language = {en},
	booktitle = {Advances in {Artificial} {Intelligence}},
	publisher = {Springer},
	author = {Japkowicz, Nathalie},
	editor = {Stroulia, Eleni and Matwin, Stan},
	year = {2001},
	keywords = {Class Imbalance , Hide Unit , Negative Class , Original Domain , Positive Class },
	pages = {67--77},
}

@article{weiss_learning_2003,
	title = {Learning {When} {Training} {Data} are {Costly}: {The} {Effect} of {Class} {Distribution} on {Tree} {Induction}},
	volume = {19},
	issn = {1076-9757},
	shorttitle = {Learning {When} {Training} {Data} are {Costly}},
	url = {https://jair.org/index.php/jair/article/view/10346},
	doi = {10.1613/jair.1199},
	abstract = {For large, real-world inductive learning problems, the number of training examples often must be limited due to the costs associated with procuring, preparing, and storing the training examples and/or the computational costs associated with learning from them. In such circumstances, one question of practical importance is: if only n training examples can be selected, in what proportion should the classes be represented?  In this article we help to answer this question by analyzing, for a fixed training-set size, the relationship between the class distribution of the training data and the performance of classification trees induced from these data. We study twenty-six data sets and, for each, determine the best class distribution for learning.  The naturally occurring class distribution is shown to generally perform well when classifier performance is evaluated using undifferentiated error rate (0/1 loss).  However, when the area under the ROC curve is used to evaluate classifier performance, a balanced distribution is shown to perform well.  Since neither of these choices for class distribution always generates the best-performing classifier, we introduce a budget-sensitive progressive sampling algorithm for selecting training examples based on the class associated with each example.  An empirical analysis of this algorithm shows that the class distribution of the resulting training set yields classifiers with good (nearly-optimal) classification performance.},
	urldate = {2021-01-31},
	journal = {Journal of Artificial Intelligence Research},
	author = {Weiss, G. M. and Provost, F.},
	month = oct,
	year = {2003},
	pages = {315--354},
}

@article{mazurowski_training_2008,
	title = {Training neural network classifiers for medical decision making: {The} effects of imbalanced datasets on classification performance},
	volume = {21},
	issn = {08936080},
	shorttitle = {Training neural network classifiers for medical decision making},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0893608007002407},
	doi = {10.1016/j.neunet.2007.12.031},
	language = {en},
	number = {2-3},
	urldate = {2021-01-31},
	journal = {Neural Networks},
	author = {Mazurowski, Maciej A. and Habas, Piotr A. and Zurada, Jacek M. and Lo, Joseph Y. and Baker, Jay A. and Tourassi, Georgia D.},
	month = mar,
	year = {2008},
	pages = {427--436},
}

@article{khreich_iterative_2010,
	title = {Iterative {Boolean} combination of classifiers in the {ROC} space: {An} application to anomaly detection with {HMMs}},
	volume = {43},
	issn = {00313203},
	shorttitle = {Iterative {Boolean} combination of classifiers in the {ROC} space},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320310001263},
	doi = {10.1016/j.patcog.2010.03.006},
	language = {en},
	number = {8},
	urldate = {2021-01-31},
	journal = {Pattern Recognition},
	author = {Khreich, Wael and Granger, Eric and Miri, Ali and Sabourin, Robert},
	month = aug,
	year = {2010},
	pages = {2732--2752},
}

@inproceedings{yi-hung_liu_total_2005,
	address = {Waikoloa, HI, USA},
	title = {Total {Margin} {Based} {Adaptive} {Fuzzy} {Support} {Vector} {Machines} for {Multiview} {Face} {Recognition}},
	volume = {2},
	isbn = {978-0-7803-9298-4},
	url = {http://ieeexplore.ieee.org/document/1571394/},
	doi = {10.1109/ICSMC.2005.1571394},
	urldate = {2021-01-31},
	booktitle = {2005 {IEEE} {International} {Conference} on {Systems}, {Man} and {Cybernetics}},
	publisher = {IEEE},
	author = {{Yi-Hung Liu} and {Yen-Ting Chen}},
	year = {2005},
	pages = {1704--1711},
}

@article{bermejo_improving_2011,
	title = {Improving the performance of {Naive} {Bayes} multinomial in e-mail foldering by introducing distribution-based balance of datasets},
	volume = {38},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417410007748},
	doi = {10.1016/j.eswa.2010.07.146},
	language = {en},
	number = {3},
	urldate = {2021-01-31},
	journal = {Expert Systems with Applications},
	author = {Bermejo, Pablo and Gámez, Jose A. and Puerta, Jose M.},
	month = mar,
	year = {2011},
	pages = {2072--2080},
}

@article{shuo_wang_multiclass_2012,
	title = {Multiclass {Imbalance} {Problems}: {Analysis} and {Potential} {Solutions}},
	volume = {42},
	issn = {1083-4419, 1941-0492},
	shorttitle = {Multiclass {Imbalance} {Problems}},
	url = {http://ieeexplore.ieee.org/document/6170916/},
	doi = {10.1109/TSMCB.2012.2187280},
	number = {4},
	urldate = {2021-01-31},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
	author = {{Shuo Wang} and {Xin Yao}},
	month = aug,
	year = {2012},
	pages = {1119--1130},
}

@article{orriols-puig_evolutionary_2009,
	title = {Evolutionary rule-based systems for imbalanced data sets},
	volume = {13},
	issn = {1432-7643, 1433-7479},
	url = {http://link.springer.com/10.1007/s00500-008-0319-7},
	doi = {10.1007/s00500-008-0319-7},
	language = {en},
	number = {3},
	urldate = {2021-01-31},
	journal = {Soft Computing},
	author = {Orriols-Puig, Albert and Bernadó-Mansilla, Ester},
	month = feb,
	year = {2009},
	pages = {213--225},
}

@article{luscombe_what_2001,
	title = {What is bioinformatics? {A} proposed definition and overview of the field},
	volume = {40},
	issn = {0026-1270},
	shorttitle = {What is bioinformatics?},
	abstract = {BACKGROUND: The recent flood of data from genome sequences and functional genomics has given rise to new field, bioinformatics, which combines elements of biology and computer science.
OBJECTIVES: Here we propose a definition for this new field and review some of the research that is being pursued, particularly in relation to transcriptional regulatory systems.
METHODS: Our definition is as follows: Bioinformatics is conceptualizing biology in terms of macromolecules (in the sense of physical-chemistry) and then applying "informatics" techniques (derived from disciplines such as applied maths, computer science, and statistics) to understand and organize the information associated with these molecules, on a large-scale.
RESULTS AND CONCLUSIONS: Analyses in bioinformatics predominantly focus on three types of large datasets available in molecular biology: macromolecular structures, genome sequences, and the results of functional genomics experiments (e.g. expression data). Additional information includes the text of scientific papers and "relationship data" from metabolic pathways, taxonomy trees, and protein-protein interaction networks. Bioinformatics employs a wide range of computational techniques including sequence and structural alignment, database design and data mining, macromolecular geometry, phylogenetic tree construction, prediction of protein structure and function, gene finding, and expression data clustering. The emphasis is on approaches integrating a variety of computational methods and heterogeneous data sources. Finally, bioinformatics is a practical discipline. We survey some representative applications, such as finding homologues, designing drugs, and performing large-scale censuses. Additional information pertinent to the review is available over the web at http://bioinfo.mbb.yale.edu/what-is-it.},
	language = {eng},
	number = {4},
	journal = {Methods of Information in Medicine},
	author = {Luscombe, N. M. and Greenbaum, D. and Gerstein, M.},
	year = {2001},
	pmid = {11552348},
	keywords = {Computational Biology, DNA-Binding Proteins, Drug Design, Gene Expression, Genomics, Humans, Sequence Homology, Terminology as Topic},
	pages = {346--358},
}

@article{nilges_bioinformatics-definition_2011,
	title = {Bioinformatics-a definition},
	abstract = {Bioinformatics derives knowledge from computer analysis of biological data. These can consist of the information stored in the genetic code, but also experimental results from various sources, patient statistics, and scientific literature. Research in bioinformatics includes method development for storage, retrieval, and analysis of the data. Bioinformatics is a rapidly developing branch of biology and is highly interdisciplinary, using techniques and concepts from informatics, statistics, mathematics, chemistry, biochemistry, physics, and linguistics. It has many practical applications in different areas of biology and medicine.},
	journal = {Unité de Bio–Informatique Structurale, Institut Pasteur},
	author = {Nilges, Michael and Linge, Jens P},
	year = {2011},
}

@article{mishra_prediction_2014,
	title = {Prediction of {Membrane} {Transport} {Proteins} and {Their} {Substrate} {Specificities} {Using} {Primary} {Sequence} {Information}},
	volume = {9},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0100278},
	doi = {10.1371/journal.pone.0100278},
	language = {en},
	number = {6},
	urldate = {2021-01-15},
	journal = {PLoS ONE},
	author = {Mishra, Nitish K. and Chang, Junil and Zhao, Patrick X.},
	editor = {Fotiadis, Dimitrios},
	month = jun,
	year = {2014},
	pages = {e100278},
}

@inproceedings{lesh_complete_2003,
	address = {Berlin, Germany},
	title = {A complete and effective move set for simplified protein folding},
	isbn = {978-1-58113-635-7},
	url = {http://portal.acm.org/citation.cfm?doid=640075.640099},
	doi = {10.1145/640075.640099},
	language = {en},
	urldate = {2021-01-15},
	booktitle = {Proceedings of the seventh annual international conference on {Computational} molecular biology  - {RECOMB} '03},
	publisher = {ACM Press},
	author = {Lesh, Neal and Mitzenmacher, Michael and Whitesides, Sue},
	year = {2003},
	pages = {188--195},
}

@book{chauvin_backpropagation_1995,
	address = {Hillsdale, N.J},
	series = {Developments in connectionist theory},
	title = {Backpropagation: theory, architectures, and applications},
	isbn = {978-0-8058-1258-9 978-0-8058-1259-6},
	shorttitle = {Backpropagation},
	publisher = {Lawrence Erlbaum Associates},
	editor = {Chauvin, Yves and Rumelhart, David E.},
	year = {1995},
	keywords = {Back propagation (Artificial intelligence)},
}

@book{baldi_bioinformatics_2001,
	address = {Cambridge, Mass},
	edition = {2nd ed},
	series = {Adaptive computation and machine learning},
	title = {Bioinformatics: the machine learning approach},
	isbn = {978-0-262-02506-5},
	shorttitle = {Bioinformatics},
	publisher = {MIT Press},
	author = {Baldi, Pierre and Brunak, Søren},
	year = {2001},
	keywords = {Bioinformatics, Computer simulation, Machine learning, Markov processes, Mathematical models, Molecular biology, Neural networks (Computer science)},
}

@article{huerta_nih_2000,
	title = {{NIH} working definition of bioinformatics and computational biology},
	abstract = {Bioinformatics and computational biology are rooted in life sciences as well as computer
and information sciences and technologies. Both of these interdisciplinary approaches
draw from specific disciplines such as mathematics, physics, computer science and
engineering, biology, and behavioral science. Bioinformatics and computational biology
each maintain close interactions with life sciences to realize their full potential.
Bioinformatics applies principles of information sciences and technologies to make the
vast, diverse, and complex life sciences data more understandable and useful.
Computational biology uses mathematical and computational approaches to address
theoretical and experimental questions in biology. Although bioinformatics and
computational biology are distinct, there is also significant overlap and activity at their
interface.},
	journal = {US National Institute of Health},
	author = {Huerta, Michael and Haseltine, Florence and Liu, Yuan and Downing, Gregory and Seto, Belinda},
	month = jul,
	year = {2000},
}

@article{larranaga_machine_2006,
	title = {Machine learning in bioinformatics},
	volume = {7},
	issn = {1467-5463},
	url = {https://academic.oup.com/bib/article/7/1/86/264025},
	doi = {10.1093/bib/bbk007},
	language = {en},
	number = {1},
	urldate = {2021-01-15},
	journal = {Briefings in Bioinformatics},
	author = {Larrañaga, Pedro and Calvo, Borja and Santana, Roberto and Bielza, Concha and Galdiano, Josu and Inza, Iñaki and Lozano, José A. and Armañanzas, Rubén and Santafé, Guzmán and Pérez, Aritz and Robles, Victor},
	month = mar,
	year = {2006},
	pages = {86--112},
}

@article{bayat_science_2002,
	title = {Science, medicine, and the future: {Bioinformatics}},
	volume = {324},
	issn = {09598138, 14685833},
	shorttitle = {Science, medicine, and the future},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.324.7344.1018},
	doi = {10.1136/bmj.324.7344.1018},
	number = {7344},
	urldate = {2021-01-15},
	journal = {BMJ},
	author = {Bayat, A.},
	month = apr,
	year = {2002},
	pages = {1018--1022},
}

@article{haibo_he_learning_2009,
	title = {Learning from {Imbalanced} {Data}},
	volume = {21},
	issn = {1041-4347},
	url = {http://ieeexplore.ieee.org/document/5128907/},
	doi = {10.1109/TKDE.2008.239},
	number = {9},
	urldate = {2021-01-15},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {{Haibo He} and Garcia, E.A.},
	month = sep,
	year = {2009},
	pages = {1263--1284},
}

@article{bayat_science_2002-1,
	title = {Science, medicine, and the future: {Bioinformatics}},
	volume = {324},
	issn = {09598138, 14685833},
	shorttitle = {Science, medicine, and the future},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.324.7344.1018},
	doi = {10.1136/bmj.324.7344.1018},
	number = {7344},
	urldate = {2021-01-12},
	journal = {BMJ},
	author = {Bayat, A.},
	month = apr,
	year = {2002},
	pages = {1018--1022},
}

@article{open_science_collaboration_estimating_2015,
	title = {Estimating the reproducibility of psychological science},
	volume = {349},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.aac4716},
	doi = {10.1126/science.aac4716},
	language = {en},
	number = {6251},
	urldate = {2020-12-31},
	journal = {Science},
	author = {{Open Science Collaboration}},
	month = aug,
	year = {2015},
	pages = {aac4716--aac4716},
}

@book{chambers_software_2008,
	address = {New York},
	series = {Statistics and computing},
	title = {Software for data analysis: programming with {R}},
	isbn = {978-0-387-75935-7},
	shorttitle = {Software for data analysis},
	publisher = {Springer},
	author = {Chambers, John M.},
	year = {2008},
	note = {OCLC: ocn191243189},
	keywords = {Data processing, Numerical analysis, R (Computer program language)},
}

@article{pedregosa_scikit-learn_2018,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	shorttitle = {Scikit-learn},
	url = {http://arxiv.org/abs/1201.0490},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.org.},
	urldate = {2020-12-31},
	journal = {arXiv:1201.0490 [cs]},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Müller, Andreas and Nothman, Joel and Louppe, Gilles and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	month = jun,
	year = {2018},
	note = {arXiv: 1201.0490},
	keywords = {Computer Science - Machine Learning, Computer Science - Mathematical Software},
}

@misc{ascb_ascb_2015,
	title = {{ASCB}	 {Member} {Survey} on {Reproducibility}},
	url = {https://www.ascb.org/wp-content/uploads/2015/11/final-survey-results-without-Q11.pdf},
	language = {English},
	publisher = {ASCB},
	author = {ASCB},
	year = {2015},
}

@article{plesser_reproducibility_2018,
	title = {Reproducibility vs. {Replicability}: {A} {Brief} {History} of a {Confused} {Terminology}},
	volume = {11},
	issn = {1662-5196},
	shorttitle = {Reproducibility vs. {Replicability}},
	url = {http://journal.frontiersin.org/article/10.3389/fninf.2017.00076/full},
	doi = {10.3389/fninf.2017.00076},
	urldate = {2020-12-31},
	journal = {Frontiers in Neuroinformatics},
	author = {Plesser, Hans E.},
	month = jan,
	year = {2018},
	pages = {76},
}

@article{olorisade_reproducibility_2017,
	title = {Reproducibility in {Machine} {Learning}-{Based} {Studies}: {An} {Example} of {Text} {Mining}},
	url = {https://openreview.net/pdf?id=By4l2PbQ-},
	abstract = {Reproducibility is an essential requirement for computational studies including those based on machine learning techniques. However, many machine learning studies are either not reproducible or are difficult to reproduce. In this paper, we consider what information about text mining studies is crucial to successful reproduction of such studies. We identify a set of factors that affect reproducibility based on our experience of attempting to reproduce six studies proposing text mining techniques for the automation of the citation screening stage in the systematic review process. Subsequently, the reproducibility of 30 studies was evaluated based on the presence or otherwise of information relating to the factors. While the studies provide useful reports of their results, they lack information on access to the dataset in the form and order as used in the original study (as against raw data), the software environment used, randomization control and the implementation of proposed techniques. In order to increase the chances of being reproduced, researchers should ensure that details about and/or access to information about these factors are provided in their reports.},
	journal = {openreview},
	author = {Olorisade, Babatunde K and Brereton, Pearl and Andras, Peter},
	year = {2017},
}

@article{alsheikh-ali_public_2011,
	title = {Public {Availability} of {Published} {Research} {Data} in {High}-{Impact} {Journals}},
	volume = {6},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0024357},
	doi = {10.1371/journal.pone.0024357},
	language = {en},
	number = {9},
	urldate = {2020-12-31},
	journal = {PLoS ONE},
	author = {Alsheikh-Ali, Alawi A. and Qureshi, Waqas and Al-Mallah, Mouaz H. and Ioannidis, John P. A.},
	editor = {Boutron, Isabelle},
	month = sep,
	year = {2011},
	pages = {e24357},
}

@article{wilkinson_fair_2016,
	title = {The {FAIR} {Guiding} {Principles} for scientific data management and stewardship},
	volume = {3},
	issn = {2052-4463},
	url = {http://www.nature.com/articles/sdata201618},
	doi = {10.1038/sdata.2016.18},
	language = {en},
	number = {1},
	urldate = {2020-12-31},
	journal = {Scientific Data},
	author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J.G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and ’t Hoen, Peter A.C and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
	month = dec,
	year = {2016},
	pages = {160018},
}

@article{mcdermott_reproducibility_2019,
	title = {Reproducibility in {Machine} {Learning} for {Health}},
	url = {http://arxiv.org/abs/1907.01463},
	abstract = {Machine learning algorithms designed to characterize, monitor, and intervene on human health (ML4H) are expected to perform safely and reliably when operating at scale, potentially outside strict human supervision. This requirement warrants a stricter attention to issues of reproducibility than other fields of machine learning. In this work, we conduct a systematic evaluation of over 100 recently published ML4H research papers along several dimensions related to reproducibility. We find that the field of ML4H compares poorly to more established machine learning fields, particularly concerning data and code accessibility. Finally, drawing from success in other fields of science, we propose recommendations to data providers, academic publishers, and the ML4H research community in order to promote reproducible research moving forward.},
	urldate = {2020-12-31},
	journal = {arXiv:1907.01463 [cs, stat]},
	author = {McDermott, Matthew B. A. and Wang, Shirly and Marinsek, Nikki and Ranganath, Rajesh and Ghassemi, Marzyeh and Foschini, Luca},
	month = jul,
	year = {2019},
	note = {arXiv: 1907.01463},
	keywords = {Computer Science - Computers and Society, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{beam_challenges_2020,
	title = {Challenges to the {Reproducibility} of {Machine} {Learning} {Models} in {Health} {Care}},
	volume = {323},
	issn = {0098-7484},
	url = {https://jamanetwork.com/journals/jama/fullarticle/2758612},
	doi = {10.1001/jama.2019.20866},
	language = {en},
	number = {4},
	urldate = {2020-12-31},
	journal = {JAMA},
	author = {Beam, Andrew L. and Manrai, Arjun K. and Ghassemi, Marzyeh},
	month = jan,
	year = {2020},
	pages = {305},
}

@article{knuth_literate_1984,
	title = {Literate {Programming}},
	volume = {27},
	issn = {0010-4620, 1460-2067},
	url = {https://academic.oup.com/comjnl/article-lookup/doi/10.1093/comjnl/27.2.97},
	doi = {10.1093/comjnl/27.2.97},
	language = {en},
	number = {2},
	urldate = {2020-12-30},
	journal = {The Computer Journal},
	author = {Knuth, D. E.},
	month = feb,
	year = {1984},
	pages = {97--111},
}

@article{gundersen_state_2018,
	title = {State of the {Art}: {Reproducibility} in {Artificial} {Intelligence}},
	url = {https://www.aaai.org/GuideBook2018/17248-73943-GB.pdf},
	abstract = {Background: Research results in artificial intelligence (AI) are criticized for not being reproducible. Objective: To quantify the state of reproducibility of empirical AI research using six reproducibility metrics measuring three different degrees of reproducibility. Hypotheses: 1) AI research is not documented well enough to reproduce the reported results. 2) Documentation practices have improved over time. Method: The literature is reviewed and a set of variables that should be documented to enable reproducibility are grouped into three …},
	journal = {aaai.org},
	author = {Gundersen, Odd Erik and Kjensmo, Sigbjørn},
	year = {2018},
	pages = {1644--1651},
}

@article{hutson_artificial_2018,
	title = {Artificial intelligence faces reproducibility crisis},
	volume = {359},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.359.6377.725},
	doi = {10.1126/science.359.6377.725},
	language = {en},
	number = {6377},
	urldate = {2020-12-30},
	journal = {Science},
	author = {Hutson, Matthew},
	month = feb,
	year = {2018},
	pages = {725--726},
}

@article{pashler_editors_2012,
	title = {Editors’ {Introduction} to the {Special} {Section} on {Replicability} in {Psychological} {Science}: {A} {Crisis} of {Confidence}?},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	shorttitle = {Editors’ {Introduction} to the {Special} {Section} on {Replicability} in {Psychological} {Science}},
	url = {http://journals.sagepub.com/doi/10.1177/1745691612465253},
	doi = {10.1177/1745691612465253},
	language = {en},
	number = {6},
	urldate = {2020-12-30},
	journal = {Perspectives on Psychological Science},
	author = {Pashler, Harold and Wagenmakers, Eric–Jan},
	month = nov,
	year = {2012},
	pages = {528--530},
}

@book{claerbout_earth_1992,
	title = {Earth soundings analysis: {Processing} versus inversion},
	volume = {6},
	url = {http://sepwww.stanford.edu/sep/prof/pvi.pdf},
	abstract = {Prospecting for petroleum is a four-step process:(1) echo soundings are recorded;(2) they are analyzed for reflections;(3) the reflections are interpreted as a geological model; and (4) the prospect is tested by drilling. The first two stages, data acquisition and analysis, are on a …},
	publisher = {Blackwell Scientific Publications London},
	author = {Claerbout, John F},
	year = {1992},
}

@article{peng_reproducible_2006,
	title = {Reproducible {Epidemiologic} {Research}},
	volume = {163},
	issn = {1476-6256, 0002-9262},
	url = {http://academic.oup.com/aje/article/163/9/783/108733/Reproducible-Epidemiologic-Research},
	doi = {10.1093/aje/kwj093},
	language = {en},
	number = {9},
	urldate = {2020-12-30},
	journal = {American Journal of Epidemiology},
	author = {Peng, Roger D. and Dominici, Francesca and Zeger, Scott L.},
	month = may,
	year = {2006},
	pages = {783--789},
}

@article{king_replication_1995,
	title = {Replication, {Replication}},
	volume = {28},
	issn = {10490965},
	url = {https://www.jstor.org/stable/420301?origin=crossref},
	doi = {10.2307/420301},
	number = {3},
	urldate = {2020-12-30},
	journal = {PS: Political Science and Politics},
	author = {King, Gary},
	month = sep,
	year = {1995},
	pages = {444},
}

@article{schwab_making_2000,
	title = {Making scientific computations reproducible},
	volume = {2},
	issn = {15219615},
	url = {http://ieeexplore.ieee.org/document/881708/},
	doi = {10.1109/5992.881708},
	number = {6},
	urldate = {2020-12-30},
	journal = {Computing in Science \& Engineering},
	author = {Schwab, M. and Karrenbach, N. and Claerbout, J.},
	month = dec,
	year = {2000},
	pages = {61--67},
}

@article{peng_reproducible_2011,
	title = {Reproducible {Research} in {Computational} {Science}},
	volume = {334},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.1213847},
	doi = {10.1126/science.1213847},
	language = {en},
	number = {6060},
	urldate = {2020-12-30},
	journal = {Science},
	author = {Peng, R. D.},
	month = dec,
	year = {2011},
	pages = {1226--1227},
}

@article{tatman_practical_2018,
	title = {A practical taxonomy of reproducibility for machine learning research},
	journal = {Open Review},
	author = {Tatman, Rachael and VanderPlas, Jake and Dane, Sohier},
	year = {2018},
}

@article{dwork_fienberg_2018,
	title = {The {Fienberg} {Problem}: {How} to {Allow} {Human} {Interactive} {Data} {Analysis} in the {Age} of {Differential} {Privacy}},
	volume = {8},
	issn = {2575-8527},
	shorttitle = {The {Fienberg} {Problem}},
	url = {https://journalprivacyconfidentiality.org/index.php/jpc/article/view/687},
	doi = {10.29012/jpc.687},
	abstract = {Differential Privacy is a popular technology for privacy-preserving analysis of large datasets. DP is powerful, but it requires that the analyst interact with data only through a special interface; in particular, the analyst does not see raw data, an uncomfortable situation for anyone trained in classical statistical data analysis. In this note we discuss the (overly) simple problem of allowing a  trusted analyst to choose an ``"interesting" statistic for popular release (the actual computation of the chosen statistic will be carried out in a differentially private way).},
	number = {1},
	urldate = {2020-12-30},
	journal = {Journal of Privacy and Confidentiality},
	author = {Dwork, Cynthia and Ullman, Jonathan},
	month = dec,
	year = {2018},
}

@article{baker_1500_2016,
	title = {1,500 scientists lift the lid on reproducibility},
	volume = {533},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/533452a},
	doi = {10.1038/533452a},
	language = {en},
	number = {7604},
	urldate = {2020-12-30},
	journal = {Nature},
	author = {Baker, Monya},
	month = may,
	year = {2016},
	pages = {452--454},
}

@article{whitaker_showing_2017,
	title = {Showing your working: a how to guide to reproducible research},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {Showing your working},
	url = {https://figshare.com/articles/presentation/Showing_your_working_A_guide_to_reproducible_neuroimaging_analyses/4244996/2},
	doi = {10.6084/M9.FIGSHARE.4244996.V2},
	abstract = {This talk will discuss the perceived and actual barriers experienced by researchers attempting to do reproducible research in neuroscience, and give practical guidance on how they can be overcome. It will include suggestions on how to make your code available and usable for others (including a strong suggestion to document it so you don't have to reply to lots of email questions from future users). Specifically it will include a brief guide to version control, collaboration and dissemination using GitHub as well as a discussion of tools to help you work reproducibly from the start in a variety of programming languages. The take home message is that \textit{\textbf{there is something you can do today to step towards making your research reproducible}}.},
	urldate = {2020-12-30},
	author = {Whitaker, Kirstie},
	year = {2017},
	note = {Artwork Size: 5527634 Bytes
Publisher: figshare},
	keywords = {170101 Biological Psychology (Neuropsychology, Psychopharmacology, Physiological Psychology), FOS: Psychology, Neuroscience},
	pages = {5527634 Bytes},
}

@article{cacioppo_social_2015,
	title = {Social, {Behavioral}, and {Economic} {Sciences} {Perspectives} on {Robust} and {Reliable} {Science}},
	url = {http://web.stanford.edu/group/bps/cgi-bin/wordpress/wp-content/uploads/2015/09/NSF-Robust-Research-Workshop-Report.pdf},
	abstract = {Scientific knowledge is cumulative. The production of each empirical finding should be viewed more as a promissory note than a final conclusion. If a scientific finding cannot be independently verified, then it cannot be regarded as an empirical fact. And if a literature contains illusory evidence rather than real findings, the efficiency of the scientific process can be compromised. In recent years, we have seen an accumulation of evidence suggesting that some scientific findings thought to be robust may in fact be illusory ...},
	journal = {stanford.edu},
	author = {Cacioppo, John T and Kaplan, Robert M and Krosnick, John A and Olds, James L and Dean, Heather},
	year = {2015},
}

@incollection{claerbout_electronic_1992,
	series = {{SEG} {Technical} {Program} {Expanded} {Abstracts}},
	title = {Electronic documents give reproducible research a new meaning},
	url = {https://library.seg.org/doi/abs/10.1190/1.1822162},
	urldate = {2020-12-30},
	booktitle = {{SEG} {Technical} {Program} {Expanded} {Abstracts} 1992},
	publisher = {Society of Exploration Geophysicists},
	author = {Claerbout, Jon F. and Karrenbach, Martin},
	month = jan,
	year = {1992},
	doi = {10.1190/1.1822162},
	pages = {601--604},
}

@article{pineau_improving_2020,
	title = {Improving {Reproducibility} in {Machine} {Learning} {Research} ({A} {Report} from the {NeurIPS} 2019 {Reproducibility} {Program})},
	url = {http://arxiv.org/abs/2003.12206},
	abstract = {One of the challenges in machine learning research is to ensure that presented and published results are sound and reliable. Reproducibility, that is obtaining similar results as presented in a paper or talk, using the same code and data (when available), is a necessary step to verify the reliability of research findings. Reproducibility is also an important step to promote open and accessible research, thereby allowing the scientific community to quickly integrate new findings and convert ideas to practice. Reproducibility also promotes the use of robust experimental workflows, which potentially reduce unintentional errors. In 2019, the Neural Information Processing Systems (NeurIPS) conference, the premier international conference for research in machine learning, introduced a reproducibility program, designed to improve the standards across the community for how we conduct, communicate, and evaluate machine learning research. The program contained three components: a code submission policy, a community-wide reproducibility challenge, and the inclusion of the Machine Learning Reproducibility checklist as part of the paper submission process. In this paper, we describe each of these components, how it was deployed, as well as what we were able to learn from this initiative.},
	urldate = {2020-12-29},
	journal = {arXiv:2003.12206 [cs, stat]},
	author = {Pineau, Joelle and Vincent-Lamarre, Philippe and Sinha, Koustuv and Larivière, Vincent and Beygelzimer, Alina and d'Alché-Buc, Florence and Fox, Emily and Larochelle, Hugo},
	month = apr,
	year = {2020},
	note = {arXiv: 2003.12206},
	keywords = {Computer Science - Machine Learning, Reproducibility, Statistics - Machine Learning},
}

@article{goodman_what_2016,
	title = {What does research reproducibility mean?},
	volume = {8},
	issn = {1946-6234, 1946-6242},
	url = {https://stm.sciencemag.org/lookup/doi/10.1126/scitranslmed.aaf5027},
	doi = {10.1126/scitranslmed.aaf5027},
	language = {en},
	number = {341},
	urldate = {2020-12-29},
	journal = {Science Translational Medicine},
	author = {Goodman, Steven N. and Fanelli, Daniele and Ioannidis, John P. A.},
	month = jun,
	year = {2016},
	keywords = {Reproducibility},
	pages = {341ps12--341ps12},
}

@article{matthews1975comparison,
  title={Comparison of the predicted and observed secondary structure of T4 phage lysozyme},
  author={Matthews, Brian W},
  journal={Biochimica et Biophysica Acta (BBA)-Protein Structure},
  volume={405},
  number={2},
  pages={442--451},
  year={1975},
  publisher={Elsevier}
}

@article{kubat1998machine,
  title={Machine learning for the detection of oil spills in satellite radar images},
  author={Kubat, Miroslav and Holte, Robert C and Matwin, Stan},
  journal={Machine learning},
  volume={30},
  number={2},
  pages={195--215},
  year={1998},
  publisher={Springer}
}