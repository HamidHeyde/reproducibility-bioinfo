\section {Conclusion}

\subsection{Data Provenance and Sharing}


    Data Provenance is a record that describes entities and processes involved in producing and delivering or otherwise influencing 
    that resource.\cite{w3c}  In other words, all the details and processes involved in putting together a dataset from the raw data. 
    We should make sure to report on the source(s) where the data (i.e. protein sequences) is taken from and the process(es) 
    by which the final data for the dataset was produced (from the original data). \\
    
    If the study involves working on dataset of sequences, then, note that a sequence could get updated several times through years. 
    So, for each sequence, the details should include the database it has been taken from (i.e. UniProt), 
    the accession number and the version. Also if any software has been involved in the curation \footnotemark process, 
    the details should be reported as mentioned in software provenance section (\ref{sec:softwareProvenance})\\
    
    \footnotetext{Data curation is the organization and integration of data collected from various sources.}    
    
    Sharing the dataset through available means would be a better practice as it saves significant amount of time when
    trying to replicate the whole experiment.
    Providing details over the curation process along with sharing the dataset would further allow the scientists to contribute to the 
    dataset by adding new sequences. The more sequences available for a problem, there would be a greater chance to develop a model 
    that could improve the stability and accuracy of the results.
    
\subsection{Feature Provenance and Sharing}

    Feature provenance refers to the historical record of how a feature is generated from the dataset. For each feature, explain 
    over the feature you are trying to extract from the dataset (i.e. Di-peptide Composition), the process details (through which the 
    feature is generated) and expected result from this process. For formulas, a clear description of the involved parameters should be 
    included in the report. If anywhere throughout the whole process, use of a random function is required, random function seed along 
    with the library details should be included. 
    Any involved coded program, software or environment related parameters should be reported as mentioned in 
    (\ref{sec:softwareProvenance}). Sharing the generated feature in any format is strongly advised.\\
    
    Describing the feature generation process along with sharing the final feature file or some certain rows from that feature ( a row 
    in a feature contains all the generated numerical values for a single input (i.e. sequence)) or providing a reference to any available 
    resource(s) (online or downloadable programs) that could produce the same numerical values, 
    would be the preferable practice as this would allow tuning the replicated pipeline to the state in which the generated results 
    would match the original ones. \\
    
    Note that some tools (being used throughout the project pipeline at the time of the experiment) might become unavailable through years. 
    Following this practice allows use of any alternative tool available at the time of the study replication (if the generated results are 
    the same as the ones being reported on the original report). Sharing the extracted feature also enables researchers to update the existing 
    program (if needed) as the updated codes could be evaluated by comparing the new generated results against the original ones.
    
\subsection{Model Provenance and Sharing}

    Model provenance refers to the historical record of how the model is trained and evaluated. This includes any possible 
    data transformation (i.e. standardization), any applied feature selection or feature engineering technique, choice of 
    the algorithm along with its hyper-parameters, the trained model and the evaluation metrics.\\
    
    Throughout the data pre-processing phase, various data transformation techniques (i.e. Standardization, Normalization, etc.)
    could be applied to the original data available in the dataset. If that is the case, then the technique 
    (i.e. Standardization (Z-score scaling)) along with any involved parameters 
    (i.e. variables calculated as (V - mean of V)/s, where "s" is the standard deviation)
    should be clearly explained. The description over how it has been applied to the original data  and the expected result 
    should be also included.\\
    
    Depending on the type of study, dealing with problems such as missing data, data with high dimensionality or imbalanced classes 
    (where there are a disproportionate ratio of observations in each class) could be the case that demands for further various techniques 
    (such as feature selection, feature engineering, imputation, etc.) to be applied to the problem. In that case, explain the applied method 
    (i.e. ensemble feature selection) along with correspondent details and parameters (i.e. explain over what type of ensemble feature selection 
    has been used including all the details). Applying the method to the original dataset and the output from this phase should also be 
    discussed in details.\\
    
    
    
    
    
    
    If a random function is used anywhere throughout the whole process, then, random function seed along 
    with the library details should be included. Any involved coded program, software or environment related parameters 
    should be reported as mentioned in (\ref{sec:softwareProvenance}). Sharing the final transformed feature set is strongly advised.
    
\subsection{Software Provenance and Sharing}
    \label{sec:softwareProvenance}

    From the data curation \footnotemark[\value{footnote}]
    and putting together a dataset, to model training and evaluation, different software and coded programs 
    could get involved in some phase of a typical Bioinformatics related problem. 
    Throughout the replication process, failing to use the same software (along with its parameters 
    being set to the same state or value at the time of the experiment) through the same environment, can also affect the final results. \\
    
    The report on this aspect should cover all the software, coded programs and libraries details being involved throughout the whole process.
    If the pipeline (\ref{sec:PipelineProvenance}) is environment-dependent, then, It should also include the environment-related 
    details in which the pipeline has been executed.\\

    A good practice (if applicable to the project) is including a "requirement.txt" file in your repository when sharing a project. 
    Working on machine learning related studies, itâ€™s common that you get a lot of libraries installed. 
    Following the instructions (available through documentation \cite{pipDoc}) you can export all the 
    installed packages and dependencies along with the current version in use into a file (Commonly named as "requirement.txt") in a state when
    the results are obtained.
    

\subsection{Pipeline Provenance and Sharing}
    \label{sec:PipelineProvenance}
    
    In software engineering, a pipeline is a chain of processing modules, in a way that so that, the output from each module is the 
    input of the next. The pipeline should be designed and coded on a modular-basis. For example, if you have a process for data cleaning, 
    feature selection or feature extraction, each one of those should be coded as an independent runnable module. The pipeline is then formed 
    by chaining all the required modules for the problem. Following this practice, if one runs through some difficulties during the replication process, 
    then there would be a greater chance for tracing and recovering from a problem associated with one piece instead of the 
    whole pipeline.\\
    
    Changing direction in an experiment or setting new targets for the study (while working on the same problem) is a common phenomenon that 
    can take place throughout any research. So, in General the entire pipeline (including all chained modules) should be reported, 
    version-controlled and shared through available means (i.e GitHub). For each module, the input to the piece, expected output, 
    the module description and any possible associated parameters should be reported. 
    Creating a walk-through guidelines for the pipeline is considered a better practice as it would walk the reader through the entire project 
    providing a brief explanation over how the whole process works.\\
    
    The common popular practice for this purpose is Notebook creation and sharing. Using applications like "Jupyter Notebook", one can create a 
    document containing live code, equations, visualizations and narrative text to walk the reader through the pipeline starting from 
    the feature extraction all the way to result generation.\\
    
    For each step, explain briefly over what the module does (could be also referenced to the correspondent part in the paper for further details) 
    followed by a runnable code cell demonstrating how to run the code. 
    If running the entire code for a piece (i.e. feature selection) is not feasible, then leave the runnable code cell there followed by 
    explanation over the matter. If this is the case, then, provide details over the expected output from this process 
    (if available, you can load and display the process result instead).\\
    
    Another alternative solution to this problem is the use of containers \footnote{OS-level virtualization is a technology through which various virtual 
    environments could be deployed on top of a shared operating system. In this type of virtualization, the underlying operating system is partitioned
    to create multiple isolated Virtual Machines (VM) providing the functionality of a physical computer system. \cite{osLevelVM}} (i.e. Docker) 
    or virtual machines \footnote{A virtual machine (VM) is an emulated computer system. Based on the computer architectures, 
    a Virtual Machine provides functionality of a physical computer \cite{virtualizationOverview}} (i.e. VMware Workstation) 
    through which researchers could create  
    a virtual computer and set up the experiment pipeline on that. They could then, leave the experiment 
    pipeline as it is (including all the involved software, coded programs and dependencies along with the environment) 
    in the state that the results are produced. 
    The experiment could then be shared through sharing the virtual environment. So, any 
    further research on the same problem could be conducted by loading the container (or the virtual machine) and running 
    the same experiment through the same environment. This would significantly speed up the process as there would be no need for  
    replication process.
    

\myparagraph{Reproducible Experiment Report Checklist}
\begin{table}[ht]
    \centering
    \begin{tabular}{| P{14cm} || p{2cm} |}
        \hline
        \rowcolor{gray}\multicolumn{2}{|L|}{Data Provenance and Sharing} \\
        \hline \hline
            \begin{itemize}
                \item
                {\small For the curation process:}
                    \begin{itemize}
                            \item
                            {\footnotesize Report on the source(s) where the data (i.e. protein sequences) is taken from }
                           \item
                            {\footnotesize Report the process(es) by which the final data for the dataset was produced (from the original data)}
                            \item
                            {\footnotesize Any involved coded program, software or environment related parameters should be reported as mentioned in (\ref{sec:softwareProvenance})}
                    \end{itemize}
                \item
                {\small If the study involves working on dataset of sequences,then for each sequence, include the database 
                it has been taken from (i.e. UniProt) along with its accession number and the version. }
                \item
                {\small  Share the final dataset and provide a link to downloadable version of the dataset.}
            \end{itemize} &\\
        \hline
        \rowcolor{gray}\multicolumn{2}{|l|}{Feature Provenance and Sharing}\\
        \hline \hline
        \begin{itemize}
                \item
                {\small For each feature:}
                    \begin{itemize}
                            \item
                            {\footnotesize Explain the concept associated with the extracted feature }
                            \item
                            {\footnotesize Explain over the process through which the feature is extracted}
                           \item
                            {\footnotesize For formulas, describe the associated parameters}
                            \item
                            {\footnotesize If a random function has been used throughout the process, report on the random seed and the library 
                            the function is used from}
                            \item
                            {\footnotesize Any involved coded program, software or environment related parameters should be reported as mentioned in (\ref{sec:softwareProvenance})}
                            \item
                            {\footnotesize Share the extracted feature file. If sharing the entire generated result is not feasible, then, 
                            share reasonable amount of rows (a row contains all the generated numerical values for a single input from the dataset) 
                            from the final extracted feature file}
                    \end{itemize}
                
            \end{itemize} &\\
        \hline
        \rowcolor{gray}\multicolumn{2}{|l|}{Model Provenance and Sharing}\\
        \hline \hline
        \multicolumn{2}{|L|}{Data Pre-processing}\\ 
        \hline
            \begin{itemize}
                    \item
                    {\small For each technique being applied to the original data in dataset:}
                        \begin{itemize}
                            \item
                            {\footnotesize Explain over the technique concept (i.e. Standardization, Ensemble feature selection, etc.) 
                            or provide reference to an available resource}
                            \item
                            {\footnotesize Explain over the technique details including any involved formulas and its parameters
                            (i.e. Z-score scaling for Standardization )}
                            \item
                            {\footnotesize Explain over how it has been applied to the original inputs}
                            \item
                            {\footnotesize If a random function is used anywhere throughout the whole process, then, random function seed along with the library details should be included.}
                            \item
                            {\footnotesize Any involved coded program, software or environment related parameters  should be reported as mentioned in (\ref{sec:softwareProvenance}). }
                            \item
                            {\footnotesize Sharing the final transformed feature set is strongly advised.}
                        \end{itemize}
            \end{itemize}&\\
        \hline
        \multicolumn{2}{|L|}{Algorithm}\\ 
        \hline
            \begin{itemize}
                \item
                {\small ??}
            \end{itemize}&\\
        \hline
        \multicolumn{2}{|L|}{Model Evaluation}\\ 
        \hline
            \begin{itemize}
                \item
                {\small ??}
            \end{itemize}&\\
        \hline

    \end{tabular}
    \captionsetup{font=small,width=12cm}
    \caption{Reproducible experiment report checklist}
    \label{tab:table3}
    
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{| P{14cm} || p{2cm} |}
        \hline
        \rowcolor{gray}\multicolumn{2}{|l|}{Software Provenance and Sharing}\\
        \hline \hline
        \multicolumn{2}{|L|}{Software}\\ 
        \hline
            \begin{itemize}
                \item 
                {\small In case of involvement of any software, the report should include software details (i.e. name, version) and a reference
                to the software documentation.} 
                \item
                {\small  If there is no documentation available, explain over what the software does, how it has been deployed in the project and  
                parameters associated with this software (if any)}
            \end{itemize} &\\
        \hline
        \multicolumn{2}{|L|}{Environment}\\ 
        \hline
            \begin{itemize}
                \item
                {\small If your pipeline is environment-dependent (it works only if certain environment available), then provide details over the 
                underlying infrastructure needed (i.e. Mac OS X 10.4 Tiger (Merlot) - 29 April 2005) and how to deploy it through that environment.}
            \end{itemize} &\\
        \hline \hline
        \rowcolor{gray}\multicolumn{2}{|l|}{Pipeline Provenance and Sharing}\\
        \hline \hline
        \multicolumn{2}{|L|}{Code Design}\\ 
        \hline
            \begin{itemize}
                \item
                {\small Design and code your pipeline as a chain of independently runnable modules (i.e. a module for feature extraction) 
                in a way that the output from each phase would be the input to the next one.}
            \end{itemize} &\\
        \hline
        \multicolumn{2}{|L|}{Pipeline Sharing}\\ 
        \hline
            \begin{itemize}
                \item
                {\small Version control and share the entire project (including the output from each phase) through available means (i.e. GitHub)}
                \item
                {\small If possible, setup your pipeline on a container (or a virtual machine) and share the entire virtual environment in 
                the state that the results are produced.}
            \end{itemize} &\\
        \hline
        \multicolumn{2}{|L|}{Pipeline Walk-through Guidelines}\\ 
        \hline
            \begin{itemize}
                \item
                {\small Create a Jupyter Notebook (or any available alternative) to walk the reader through the pipeline 
                starting from the feature extraction all the way to result generation. for each step:}
                    \begin{itemize}
                        \item
                        {\footnotesize Explain briefly what the code does (or make a reference to the correspondent part in the paper) 
                        followed by a runnable code cell demonstrating how to run the code.}
                       \item
                        {\footnotesize If running the entire code for a part (i.e. feature selection) is not feasible, then leave the runnable 
                        code cell there and explain why it is not feasible to run it through the notebook. Also, explain over the expected output 
                        from this process (if available, you can load and display the process result instead)}
                \end{itemize}
                
                 \item
                {\small If possible, host your pipeline on a container (or a virtual machine) and share the entire virtual environment instead.}
            \end{itemize} &\\
        \hline

    \end{tabular}
    \captionsetup{font=small,width=12cm}
    \caption{Reproducible experiment report checklist (continued)}
    \label{tab:table3}
    
\end{table}